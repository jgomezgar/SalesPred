{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for evaluate a model trained.\n",
    "\n",
    "The same process of transformation of the test data is followed as was done for the training data for the correct functioning of the model prediction. The results will reflect the true effectiveness of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GroupKFold, cross_val_score\n",
    "import lightgbm as ltb\n",
    "import matplotlib.pyplot as plt \n",
    "import joblib\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From an fitted model makes a prediction and returns the results.\n",
    "    \n",
    "    Parameters:\n",
    "        model: Model object fitted.\n",
    "        X: Data with the independent variables to predict\n",
    "        y: Data with the dependient variable to compare with the prediction\n",
    "        thresholds: List of thresholds where to check for each of them, the \n",
    "        number of records of X below them.\n",
    "        verbose: Defines whether or not the output is displayed.\n",
    "    \n",
    "    Returns:\n",
    "        results: Pandas Dataframe with the results of the predictions:\n",
    "            - REAL: Real value of dependent variable.\n",
    "            - PRED: Prediction value of dependent variable.\n",
    "            - PERCENTAGE_ERROR:  Percentage deviation mean error by row from REAL and PRED.\n",
    "            - ABSOLUTE_ERROR: Absolute mean error by row from REAL and PRED.\n",
    "            - R2_SCORE: R square score from REAL and PRED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X, y, thresholds=[5], verbose=1):\n",
    "    y_pred = model.predict(X)\n",
    "    y = np.power(y,3)\n",
    "    y_pred = np.power(y_pred,3)\n",
    "    porc_error = abs(y_pred - y)*100/y\n",
    "    absolute_mean_error = mean_absolute_error(y, y_pred)\n",
    "    porcentual_mean_error = np.mean(porc_error[porc_error != np.inf])\n",
    "    if verbose:\n",
    "        print(\"\\nTEST: Absolute Error:\", absolute_mean_error)\n",
    "        print(\"Porcentual Error:\", porcentual_mean_error)\n",
    "        print(\"STD Error:\", np.std(abs(y - y_pred)))\n",
    "        print(\"R2 Score:\", r2_score(y, y_pred)) #Coef determ\n",
    "    results = pd.DataFrame(np.array(y), columns = ['REAL'])\n",
    "    results['PRED'] = y_pred\n",
    "    results['PERCENTAGE_ERROR'] = np.abs(results['PRED'] - results['REAL'])*100/results['REAL'] \n",
    "    results['ABSOLUTE_ERROR'] = np.abs(results['PRED'] - results['REAL'])*100\n",
    "    results['R2_SCORE'] = r2_score(results['REAL'], results['PRED'])\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        hits = 0\n",
    "        for element in results['ABSOLUTE_ERROR']:\n",
    "            if element <= threshold:\n",
    "                hits+=1\n",
    "        \n",
    "        porcentual_hits = hits*100/len(results)\n",
    "        if verbose:\n",
    "            print(str(porcentual_hits)+str(\"% registers are with less than\"), str(threshold)+str(\"% of absolute error.\"))\n",
    "            results['% REG ERROR < '+str(threshold)] = porcentual_hits\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define INPUT and OUTPUT files\n",
    "INPUT = '../02_Data/prepared_train.csv'\n",
    "INPUT_FEATS = '../02_Data/features.npy'\n",
    "OUTPUT_MODEL = '../02_Data/model.pkl'\n",
    "OUTPUT_SC = '../02_Data/sc_X.bin'\n",
    "OUTPUT_TRAIN_RES = '../02_Data/train_results.csv'\n",
    "OUTPUT_VAL_RES = '../02_Data/val_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read best features from feature selection\n",
    "features = np.load(INPUT_FEATS).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data resetting the indexes\n",
    "data = pd.read_csv(INPUT, sep='|').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing the independent and dependent variables in X and y respectively\n",
    "X = data[features + ['CUSTOMER_ID','BRANDFAMILY_ID']]\n",
    "y = data['QUOTA_SELLOUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unique customers and shuffle them\n",
    "customers = X['CUSTOMER_ID'].drop_duplicates().reset_index(drop=True)\n",
    "index = np.random.permutation(len(customers))\n",
    "customers = customers.loc[index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train and val customers by ratio\n",
    "ratio = 0.9\n",
    "train = customers[:int(np.round(len(customers)*ratio))]\n",
    "val = customers[int(np.round(len(customers)*ratio)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4925    36050037\n",
       "4926    28007268\n",
       "4927    15130222\n",
       "4928    46040689\n",
       "4929    47030119\n",
       "          ...   \n",
       "5467    48001911\n",
       "5468     8090326\n",
       "5469    27070085\n",
       "5470    46002556\n",
       "5471    14000418\n",
       "Name: CUSTOMER_ID, Length: 547, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       46030177\n",
       "1       20010427\n",
       "2        3040342\n",
       "3        7005093\n",
       "4       48020325\n",
       "          ...   \n",
       "4920     8030322\n",
       "4921     3010501\n",
       "4922    15000599\n",
       "4923    31000037\n",
       "4924    28007227\n",
       "Name: CUSTOMER_ID, Length: 4925, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the indexes of the dataset where the customers are located\n",
    "index_train = X['CUSTOMER_ID'].isin(train)\n",
    "index_val = X['CUSTOMER_ID'].isin(val)\n",
    "\n",
    "X_train = X[index_train].reset_index(drop=True)\n",
    "X_val = X[index_val].reset_index(drop=True)\n",
    "\n",
    "y_train = y[index_train].reset_index(drop=True)\n",
    "y_val = y[index_val].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create peer groups of customers for cross-validation\n",
    "groups = X_train.CUSTOMER_ID\n",
    "group_KFold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove CUSTOMER_ID from data\n",
    "X_train = X_train.drop(['CUSTOMER_ID','BRANDFAMILY_ID'], axis=1)\n",
    "X_val = X_val.drop(['CUSTOMER_ID','BRANDFAMILY_ID'], axis=1)\n",
    "X = X.drop(['CUSTOMER_ID','BRANDFAMILY_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a data scaling with StandardScaler on X_train and transform on X_val\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_val = sc_X.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_Data/sc_X.bin']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save StandardScaler configuration to file for future use\n",
    "joblib.dump(sc_X, OUTPUT_SC, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform train and val dependent variable to a gaussian distribution\n",
    "y_train = y_train**(float(1)/3)\n",
    "y_val = y_val**(float(1)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean to choose the use of gridsearch\n",
    "grid_search = False\n",
    "if grid_search:\n",
    "    # Define parameters for the gridsearch\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'num_leaves': [12, 16, 31],\n",
    "        'random_state' : [501],\n",
    "        'colsample_bytree' : [0.65, 0.66, 1.0],\n",
    "        'subsample' : [0.75, 1.0],\n",
    "        'reg_alpha' : [0.0, 1.0, 1.2],\n",
    "        'reg_lambda' : [0.0, 1.0, 1.2],\n",
    "    }\n",
    "    # Define the estimator base model\n",
    "    estimator = ltb.LGBMRegressor()\n",
    "    \n",
    "    # Define de type of gridsearch (RandomizedSearchCV) and fit for get the best parameters\n",
    "    model = RandomizedSearchCV(estimator = estimator, param_distributions = param_grid, n_iter = 50, cv = group_KFold.split(X_train, y_train, groups), verbose=1, random_state=27, n_jobs = -1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator into model\n",
    "    model = model.best_estimator_\n",
    "    \n",
    "    # Check the scores of the model with cross validation and R squared metric on train data\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=group_KFold.split(X_train, y_train, groups), scoring='r2')    \n",
    "    \n",
    "\n",
    "else:\n",
    "    # Define predefined model\n",
    "    model = ltb.LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
    "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
    "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "    \n",
    "    # Check the scores of the model with cross validation and R squared metric on train data\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=group_KFold.split(X_train, y_train, groups), scoring='r2')     \n",
    "       \n",
    "    # Fit the model with train data\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../02_Data/model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model configuration to file for future use\n",
    "joblib.dump(model, OUTPUT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST: Absolute Error: 0.01505422293243398\n",
      "Porcentual Error: 45.486742884187365\n",
      "STD Error: 0.02375558758113329\n",
      "R2 Score: 0.9005759901691001\n",
      "59.771229674359255% registers are with less than 1% of absolute error.\n",
      "78.03592529944602% registers are with less than 2% of absolute error.\n",
      "93.68093079184928% registers are with less than 5% of absolute error.\n",
      "98.71718162078861% registers are with less than 10% of absolute error.\n",
      "\n",
      "TEST: Absolute Error: 0.014784552250040281\n",
      "Porcentual Error: 45.47092892662934\n",
      "STD Error: 0.023145922883882626\n",
      "R2 Score: 0.8994779543760659\n",
      "59.877656353101756% registers are with less than 1% of absolute error.\n",
      "78.3015158499878% registers are with less than 2% of absolute error.\n",
      "94.01501387495368% registers are with less than 5% of absolute error.\n",
      "98.83079787762924% registers are with less than 10% of absolute error.\n"
     ]
    }
   ],
   "source": [
    "# Get results from evaluate the model with train and val data\n",
    "res_train = eval_model(model, X_train, y_train, [1, 2, 5, 10], verbose=1)\n",
    "res_val = eval_model(model, X_val, y_val, [1, 2, 5, 10], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format results dataframes for write to file\n",
    "res_train = data[index_train][['CUSTOMER_ID','BRANDFAMILY_ID','CAL_DATE','CAL_DATE_end']].reset_index(drop=True).merge(res_train, left_index=True, right_index=True)\n",
    "res_val = data[index_val][['CUSTOMER_ID','BRANDFAMILY_ID','CAL_DATE','CAL_DATE_end']].reset_index(drop=True).merge(res_val, left_index=True, right_index=True)\n",
    "\n",
    "res_train['CV_R2_SCORE'] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is written to a file\n",
    "res_train.to_csv(OUTPUT_TRAIN_RES, sep='|', index=False)\n",
    "res_val.to_csv(OUTPUT_VAL_RES, sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute script: 0.11 h\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "print (\"Time to execute script:\",str(round((t2-t1)/3600,2)), \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
